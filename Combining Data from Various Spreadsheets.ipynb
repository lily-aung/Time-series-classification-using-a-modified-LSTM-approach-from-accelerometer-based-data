{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data from Various Spreadsheets\n",
    "\n",
    "In this notebook, we will combine data from the MAREA dataset. Data is stored in the following three files:\n",
    "1. Subject Data\n",
    "2. Activity Timings\n",
    "3. Ground Truth\n",
    "\n",
    "We write code to combine the data for one subject and apply the same code to each subject (20 in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the subject ID whose data you want to convert\n",
    "SUBJECT_ID = '20'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Combine Activity Data of each Subject\n",
    "\n",
    "The readings from each accelerometer (LF, RF, Waist and Wrist) are stored in separate text files for each subject under Subject Data.\n",
    "\n",
    "Firstly, we combine these data into a single table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The readings from each accelerometer (LF, RF, Waist and Wrist) are stored in separate text files for each subject\n",
    "# Firstly, we combine these data into a single table\n",
    "\n",
    "ACTIVITY_PATH = './Subject Data_txt format/'\n",
    "LF_FILE = ACTIVITY_PATH + 'Sub' + SUBJECT_ID + '_LF.txt'\n",
    "RF_FILE = ACTIVITY_PATH + 'Sub' + SUBJECT_ID + '_RF.txt'\n",
    "Waist_FILE = ACTIVITY_PATH + 'Sub' + SUBJECT_ID + '_Waist.txt'\n",
    "Wrist_FILE = ACTIVITY_PATH + 'Sub' + SUBJECT_ID + '_Wrist.txt' # Comment out for subject 4\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read in the data into dataframe\n",
    "LF_DATA = pd.read_csv(LF_FILE, header = 0)\n",
    "RF_DATA = pd.read_csv(RF_FILE, header = 0)\n",
    "Waist_DATA = pd.read_csv(Waist_FILE, header = 0)\n",
    "Wrist_DATA = pd.read_csv(Wrist_FILE, header = 0) # Comment out for subject 4\n",
    "\n",
    "# print (LF_DATA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the column headings are accX, accY, accZ, we will need to rename them to know which accelerometer they came from\n",
    "# To that we add a \"_LF/RF/Waist/Wrist\"\n",
    "\n",
    "LF_DATA_2 = LF_DATA.rename(index=str, columns={\"accX\": \"accX_LF\", \"accY\": \"accY_LF\", \"accZ\": \"accZ_LF\"})\n",
    "RF_DATA_2 = RF_DATA.rename(index=str, columns={\"accX\": \"accX_RF\", \"accY\": \"accY_RF\", \"accZ\": \"accZ_RF\"})\n",
    "Waist_DATA_2 = Waist_DATA.rename(index=str, columns={\"accX\": \"accX_Waist\", \"accY\": \"accY_Waist\", \"accZ\": \"accZ_Waist\"})\n",
    "Wrist_DATA_2 = Wrist_DATA.rename(index=str, columns={\"accX\": \"accX_Wrist\", \"accY\": \"accY_Wrist\", \"accZ\": \"accZ_Wrist\"}) # Comment out for subject 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accX_LF  accY_LF  accZ_LF  accX_RF  accY_RF  accZ_RF  accX_Waist  \\\n",
      "0  -26.039  -23.373   -3.765   -4.392  -10.510   -2.353      -0.627   \n",
      "1  -29.020  -19.294   -1.098   -4.549  -10.667   -2.196      -0.471   \n",
      "2  -30.588  -17.569    0.471   -4.235  -10.667   -2.510      -0.627   \n",
      "3  -32.941  -13.804    5.176   -5.333  -11.137   -1.725      -0.784   \n",
      "4  -34.196  -11.765    5.647   -5.176  -11.294   -2.353      -0.784   \n",
      "\n",
      "   accY_Waist  accZ_Waist  accX_Wrist  accY_Wrist  accZ_Wrist  \n",
      "0      -6.118       1.412       8.000       0.941       3.451  \n",
      "1      -5.961       1.255       7.843       1.255       3.451  \n",
      "2      -6.275       0.941       7.529       1.412       3.137  \n",
      "3      -6.118       0.941       7.373       1.569       3.137  \n",
      "4      -6.275       1.098       7.059       1.725       3.137  \n"
     ]
    }
   ],
   "source": [
    "# Merge the columns together\n",
    "\n",
    "ACTIVITY_DATA = pd.concat([LF_DATA_2, RF_DATA_2, Waist_DATA_2, Wrist_DATA_2], axis=1, sort=False)\n",
    "#ACTIVITY_DATA = pd.concat([LF_DATA_2, RF_DATA_2, Waist_DATA_2], axis=1, sort=False) # for subject 4 only\n",
    "print(ACTIVITY_DATA.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Place an indicator for each type of activity\n",
    "\n",
    "The Activity Timings dataset shows when the subject is carrying out a particular activity (Walk/Run).\n",
    "\n",
    "We will look up the timings for each subject and create a binary variable for each activity, 1 being that the activity is being carried out at that point in time, 0 otherwise.\n",
    "\n",
    "We will also add in the sample number for each activity. These fields end with \"index\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject_Id:20\n",
      "Walk:1\n",
      "Walk_End:23401\n",
      "Walk_Run:32201\n"
     ]
    }
   ],
   "source": [
    "# The Activity Timings dataset shows when the subject is carrying out a particular activity (Walk/Run). \n",
    "# We will look up the timings for each subject and create a binary variable for each activity to indicate \n",
    "# whether that activity is currently being carried out\n",
    "# We will also add in the sample number for each activity. \n",
    "# These fields end with \"index\"\n",
    "\n",
    "TIMINGS_PATH = './Activity Timings_csv format/'\n",
    "\n",
    "# ######Indoors######\n",
    "\n",
    "# # read in the data into dataframe\n",
    "# TIMINGS_DATA = pd.read_csv(TIMINGS_PATH + 'Indoor Experiment Timings.csv', header = 0)\n",
    "\n",
    "# # Get subject-specific timings\n",
    "# WALK = int(TIMINGS_DATA['Walk'][TIMINGS_DATA.index[int(SUBJECT_ID)-1]])\n",
    "# WALK_END = int(TIMINGS_DATA['Walk_End'][TIMINGS_DATA.index[int(SUBJECT_ID)-1]])\n",
    "# WALK_RUN = int(TIMINGS_DATA['Walk_Run'][TIMINGS_DATA.index[int(SUBJECT_ID)-1]])\n",
    "# SLOPE = int(TIMINGS_DATA['Slope'][TIMINGS_DATA.index[int(SUBJECT_ID)-1]])\n",
    "# SLOPE_END = int(TIMINGS_DATA['Slope_End'][TIMINGS_DATA.index[int(SUBJECT_ID)-1]])\n",
    "# FLAT = int(TIMINGS_DATA['Flat'][TIMINGS_DATA.index[int(SUBJECT_ID)-1]])\n",
    "# FLAT_END = int(TIMINGS_DATA['Flat_End'][TIMINGS_DATA.index[int(SUBJECT_ID)-1]])\n",
    "# FLAT_RUN = int(TIMINGS_DATA['Flat_Run'][TIMINGS_DATA.index[int(SUBJECT_ID)-1]])\n",
    "\n",
    "# print('Subject_Id:' + str(SUBJECT_ID))\n",
    "# print('Walk:' + str(WALK))\n",
    "# print('Walk_End:' + str(WALK_END))\n",
    "# print('Walk_Run:' + str(WALK_RUN))\n",
    "# print('Slope:' + str(SLOPE))\n",
    "# print('Slope_End:' + str(SLOPE_END))\n",
    "# print('Flat:' + str(FLAT))\n",
    "# print('Flat_End:' + str(FLAT_END))\n",
    "# print('Flat_Run:' + str(FLAT_RUN))\n",
    "\n",
    "# ######Outdoors######\n",
    "\n",
    "# read in the data into dataframe\n",
    "TIMINGS_DATA = pd.read_csv(TIMINGS_PATH + 'Outdoor Experiment Timings.csv', header = 0)\n",
    "\n",
    "# Get subject-specific timings\n",
    "WALK = int(TIMINGS_DATA['Walk'][TIMINGS_DATA.index[int(SUBJECT_ID)-12]])\n",
    "WALK_END = int(TIMINGS_DATA['Walk_End'][TIMINGS_DATA.index[int(SUBJECT_ID)-12]])\n",
    "WALK_RUN = int(TIMINGS_DATA['Walk_Run'][TIMINGS_DATA.index[int(SUBJECT_ID)-12]])\n",
    "\n",
    "print('Subject_Id:' + str(SUBJECT_ID))\n",
    "print('Walk:' + str(WALK))\n",
    "print('Walk_End:' + str(WALK_END))\n",
    "print('Walk_Run:' + str(WALK_RUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to create binary variable and index\n",
    "\n",
    "def get_binary (activity_as_string, start_time, end_time):\n",
    "    global ACTIVITY_DATA\n",
    "    temp_list = []\n",
    "    for i in range(len(ACTIVITY_DATA)):\n",
    "        if i+1 >= start_time and i+1 <= end_time:\n",
    "            temp_list.append(1)\n",
    "        else:\n",
    "            temp_list.append(0)\n",
    "    ACTIVITY_DATA[activity_as_string] = temp_list\n",
    "    \n",
    "def get_index (activity_as_string, start_time, end_time):\n",
    "    global ACTIVITY_DATA\n",
    "    counter = 1\n",
    "    temp_list = []\n",
    "    for i in range(len(ACTIVITY_DATA)):\n",
    "        if i+1 >= start_time and i+1 <= end_time:\n",
    "            temp_list.append(counter)\n",
    "            counter+=1\n",
    "        else:\n",
    "            temp_list.append(0)\n",
    "    ACTIVITY_DATA[activity_as_string+'_index'] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Indoors######\n",
    "\n",
    "# # treadmill_walk\n",
    "# get_binary ('treadmill_walk', WALK, WALK_END)\n",
    "# get_index ('treadmill_walk', WALK, WALK_END)\n",
    "\n",
    "# # treadmill_walknrun\n",
    "# get_binary ('treadmill_walknrun', WALK, WALK_RUN)\n",
    "# get_index ('treadmill_walknrun', WALK, WALK_RUN)\n",
    "\n",
    "# # treadmill_slope_walk\n",
    "# get_binary ('treadmill_slope_walk', SLOPE, SLOPE_END)\n",
    "# get_index ('treadmill_slope_walk', SLOPE, SLOPE_END)\n",
    "\n",
    "# # indoor_walk\n",
    "# get_binary ('indoor_walk', FLAT, FLAT_END)\n",
    "# get_index ('indoor_walk', FLAT, FLAT_END)\n",
    "\n",
    "# # indoor_walknrun\n",
    "\n",
    "# get_binary ('indoor_walknrun', FLAT, FLAT_RUN)\n",
    "# get_index ('indoor_walknrun', FLAT, FLAT_RUN)\n",
    "\n",
    "######Outdoors######\n",
    "# outdoor_walk\n",
    "get_binary ('outdoor_walk', WALK, WALK_END)\n",
    "get_index ('outdoor_walk', WALK, WALK_END)\n",
    "\n",
    "# outdoor_walknrun\n",
    "get_binary ('outdoor_walknrun', WALK, WALK_RUN)\n",
    "get_index ('outdoor_walknrun', WALK, WALK_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accX_LF                       5.804\n",
       "accY_LF                     -21.333\n",
       "accZ_LF                      -4.706\n",
       "accX_RF                      -4.706\n",
       "accY_RF                      -6.902\n",
       "accZ_RF                     -14.118\n",
       "accX_Waist                   -3.137\n",
       "accY_Waist                  -19.765\n",
       "accZ_Waist                    9.098\n",
       "accX_Wrist                   20.392\n",
       "accY_Wrist                  -40.941\n",
       "accZ_Wrist                  -16.941\n",
       "outdoor_walk                  0.000\n",
       "outdoor_walk_index            0.000\n",
       "outdoor_walknrun              1.000\n",
       "outdoor_walknrun_index    23692.000\n",
       "Name: 23691, dtype: float64"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIVITY_DATA.iloc[23691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_PATH = './Combined Data_csv format/'\n",
    "# ACTIVITY_DATA.to_csv(SAVE_PATH + \"Sub_\" + SUBJECT_ID + \"testing.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Place an indicator for Heel-Strikes and Toe-Offs\n",
    "\n",
    "The Ground Truth datasets show the timings of Heel Strikes (HS) and Toe-offs (TO) for each foot (LF and RF). \n",
    "We introduce another variable to the dataset to indicate whether there is a Heel Strike or Toe Off happening at each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "GROUND_TRUTH_PATH = './GroundTruth_csv format/'\n",
    "\n",
    "# ######Indoors######\n",
    "# TREADMILL_WALKNRUN_GT = pd.read_csv(GROUND_TRUTH_PATH + SUBJECT_ID + '_treadWalknRun.csv', header = 0)\n",
    "# TREADMILL_SLOPE_WALK_GT = pd.read_csv(GROUND_TRUTH_PATH + SUBJECT_ID + '_treadIncline.csv', header = 0)\n",
    "# INDOOR_WALKNRUN_GT = pd.read_csv(GROUND_TRUTH_PATH + SUBJECT_ID + '_indoorWalknRun.csv', header = 0)\n",
    "\n",
    "# TREADMILL_WALKNRUN_GT = TREADMILL_WALKNRUN_GT.dropna().astype(int)\n",
    "# TREADMILL_SLOPE_WALK_GT = TREADMILL_SLOPE_WALK_GT.dropna().astype(int)\n",
    "# INDOOR_WALKNRUN_GT = INDOOR_WALKNRUN_GT.dropna().astype(int)\n",
    "\n",
    "######Outdoors######\n",
    "OUTDOOR_WALKNRUN_GT = pd.read_csv(GROUND_TRUTH_PATH + SUBJECT_ID + '_outdoorWalknRun.csv', header = 0)\n",
    "\n",
    "OUTDOOR_WALKNRUN_GT = OUTDOOR_WALKNRUN_GT.dropna().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the indicator variables for heel strike or toe offs\n",
    "\n",
    "# ######Indoors######\n",
    "# def get_hsto(foot_event_as_string):\n",
    "#     global TREADMILL_WALKNRUN_GT, TREADMILL_SLOPE_WALK_GT, INDOOR_WALKNRUN_GT, ACTIVITY_DATA\n",
    "    \n",
    "#     TREADMILL_WALKNRUN_GT[foot_event_as_string + '_twr_indicator'] =1 \n",
    "#     TREADMILL_SLOPE_WALK_GT[foot_event_as_string + '_tsw_indicator'] =1 \n",
    "#     INDOOR_WALKNRUN_GT[foot_event_as_string + '_iwr_indicator'] =1 \n",
    "    \n",
    "#     ACTIVITY_DATA = pd.merge(ACTIVITY_DATA, TREADMILL_WALKNRUN_GT[[foot_event_as_string,foot_event_as_string + '_twr_indicator']], left_on='treadmill_walknrun_index',right_on=foot_event_as_string, how = 'left')\n",
    "#     ACTIVITY_DATA = ACTIVITY_DATA.drop(foot_event_as_string, 1)\n",
    "#     ACTIVITY_DATA = pd.merge(ACTIVITY_DATA, TREADMILL_SLOPE_WALK_GT[[foot_event_as_string,foot_event_as_string + '_tsw_indicator']], left_on='treadmill_slope_walk_index',right_on=foot_event_as_string, how = 'left')\n",
    "#     ACTIVITY_DATA = ACTIVITY_DATA.drop(foot_event_as_string, 1)\n",
    "#     ACTIVITY_DATA = pd.merge(ACTIVITY_DATA, INDOOR_WALKNRUN_GT[[foot_event_as_string,foot_event_as_string + '_iwr_indicator']], left_on='indoor_walknrun_index',right_on=foot_event_as_string, how = 'left')\n",
    "#     ACTIVITY_DATA = ACTIVITY_DATA.drop(foot_event_as_string, 1)\n",
    "#     ACTIVITY_DATA = ACTIVITY_DATA.fillna(0)\n",
    "    \n",
    "#     ACTIVITY_DATA[foot_event_as_string]=ACTIVITY_DATA[foot_event_as_string+ '_twr_indicator']+ACTIVITY_DATA[foot_event_as_string+ '_tsw_indicator']+ACTIVITY_DATA[foot_event_as_string+ '_iwr_indicator']\n",
    "#     ACTIVITY_DATA = ACTIVITY_DATA.drop([foot_event_as_string + '_twr_indicator', foot_event_as_string + '_tsw_indicator', foot_event_as_string + '_iwr_indicator'], 1)\n",
    "    \n",
    "######Outdoors######\n",
    "def get_hsto(foot_event_as_string):\n",
    "    global OUTDOOR_WALKNRUN_GT, ACTIVITY_DATA\n",
    "    \n",
    "    OUTDOOR_WALKNRUN_GT['indicator'] =1 \n",
    "\n",
    "    ACTIVITY_DATA = pd.merge(ACTIVITY_DATA, OUTDOOR_WALKNRUN_GT[[foot_event_as_string,'indicator']], left_on='outdoor_walknrun_index',right_on=foot_event_as_string, how = 'left')\n",
    "    ACTIVITY_DATA = ACTIVITY_DATA.drop(foot_event_as_string, 1)\n",
    "    ACTIVITY_DATA = ACTIVITY_DATA.fillna(0)\n",
    "    \n",
    "    ACTIVITY_DATA[foot_event_as_string]=ACTIVITY_DATA['indicator']\n",
    "    ACTIVITY_DATA = ACTIVITY_DATA.drop(['indicator'], 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute functions\n",
    "get_hsto('LF_HS')\n",
    "get_hsto('RF_HS')\n",
    "get_hsto('LF_TO')\n",
    "get_hsto('RF_TO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Save the Data\n",
    "\n",
    "Now that we have our dataet, we will save it in the folder 'Combined Data_csv format'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = './Combined Data_csv format/'\n",
    "ACTIVITY_DATA.to_csv(SAVE_PATH + \"Sub_\" + SUBJECT_ID + \".csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
